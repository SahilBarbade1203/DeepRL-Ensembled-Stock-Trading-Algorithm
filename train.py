{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOc/hMtol3YNZWo7YN0wic1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"s13DL3CEQbum"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset,DataLoader\n","import torch.optim as optim\n","\n","import yfinance as yf\n","from collections import deque\n","import random\n","import math\n","from tqdm import tqdm\n","\n","dataset_dir = \"/content/drive/MyDrive/Deep_RL_for_Stock_Trading\"\n","\n","# Define the ticker symbol for NIFTY50\n","nifty50_ticker = \"^NSEI\"\n","\n","# Download the historical data for NIFTY50\n","nifty50_data = yf.download(nifty50_ticker, start=\"2010-01-01\", end=\"2019-08-08\")\n","\n","plt.plot(nifty50_data['Close'])\n","plt.show()\n","\n","file_name = f\"{dataset_dir}/data.csv\"\n","\n","# Save the DataFrame to a CSV file\n","nifty50_data.to_csv(file_name, index=False)\n","\n","print(f\"File Saved at {file_name}\")\n","\n","#Data Cleaning and EDA\n","null_values = nifty50_data.isna().values.any()\n","print(f\"Presence of Null value : {int(null_values)}\")\n","\n","if null_values:\n","  nifty50_data = nifty50_data.fillna(method = \"ffill\")\n","\n","#data splitting in 80-20% fashion for training and testing\n","X=list(nifty50_data[\"Close\"])\n","data=[float(x) for x in X]\n","test_size = 0.2\n","\n","train_data = data[:int(len(data)*(1-test_size))]\n","test_data = data[int(len(data)*(1-test_size)):]\n","\n","print(f\"Training Data shape : {len(train_data)} and Testing Data Shape : {len(test_data)}\")\n","\n","#training agents (note : replace DQN with required agent names)\n","#hyperparameters and agent,state intialization\n","window_size = 10\n","agent = DQN_Agent(window_size)\n","data = train_data  # Assuming train_data is defined somewhere\n","episode_count = 10\n","l = len(data) - 1\n","batch_size = 32\n","\n","losses = []\n","profits = []\n","\n","for e in range(episode_count):\n","    print(f\"Running episode {e + 1}/{episode_count}\")\n","    state = getState(data, 0, window_size + 1)\n","    total_profit = 0\n","    agent_inventory = []\n","    states_sell = []\n","    states_buy = []\n","\n","    for t in range(l):\n","        action = agent.act(state)\n","        next_state = getState(data, t + 1, window_size + 1)\n","        reward = 0\n","\n","        if action == 1:  # buy\n","            agent_inventory.append(data[t])\n","            states_buy.append(t)\n","\n","        elif action == 2 and len(agent_inventory) > 0:  # sell\n","            bought_price = agent_inventory.pop(0)\n","            reward = max(data[t] - bought_price, 0)\n","            total_profit += data[t] - bought_price\n","            states_sell.append(t)\n","\n","        done = t == l - 1\n","        agent.remember(state, action, reward, next_state, done)\n","        state = next_state\n","\n","        if done:\n","            print(\"--------------------------------\")\n","            print(f\"Total Profit: {total_profit:.2f}\")\n","            profits.append(total_profit)\n","            print(\"--------------------------------\")\n","\n","            plot_behavior(data, states_buy, states_sell, total_profit)\n","\n","        if len(agent.memory) > batch_size:\n","            loss = agent.experience_replay(batch_size)\n","            losses.append(loss)\n","\n","    if e % 2 == 0:\n","        torch.save(agent.model.state_dict(), f\"{dataset_dir}/model_ep{e}.pth\")"]}]}