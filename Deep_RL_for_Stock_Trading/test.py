{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtApn2XftKuBxiAc7LU7Ns"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iHZ97-blRHEm"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset,DataLoader\n","import torch.optim as optim\n","\n","import yfinance as yf\n","from collections import deque\n","import random\n","import math\n","from tqdm import tqdm\n","\n","dataset_dir = \"/content/drive/MyDrive/Deep_RL_for_Stock_Trading\"\n","\n","# Define the ticker symbol for NIFTY50\n","nifty50_ticker = \"^NSEI\"\n","\n","# Download the historical data for NIFTY50\n","nifty50_data = yf.download(nifty50_ticker, start=\"2010-01-01\", end=\"2019-08-08\")\n","\n","plt.plot(nifty50_data['Close'])\n","plt.show()\n","\n","file_name = f\"{dataset_dir}/data.csv\"\n","\n","# Save the DataFrame to a CSV file\n","nifty50_data.to_csv(file_name, index=False)\n","\n","print(f\"File Saved at {file_name}\")\n","\n","#Data Cleaning and EDA\n","null_values = nifty50_data.isna().values.any()\n","print(f\"Presence of Null value : {int(null_values)}\")\n","\n","if null_values:\n","  nifty50_data = nifty50_data.fillna(method = \"ffill\")\n","\n","#data splitting in 80-20% fashion for training and testing\n","X=list(nifty50_data[\"Close\"])\n","data=[float(x) for x in X]\n","test_size = 0.2\n","\n","train_data = data[:int(len(data)*(1-test_size))]\n","test_data = data[int(len(data)*(1-test_size)):]\n","\n","print(f\"Training Data shape : {len(train_data)} and Testing Data Shape : {len(test_data)}\")\n","\n","#testing\n","\n","#agent is already defined in the training set above.\n","l_test = len(test_data) - 1\n","state = getState(test_data, 0, window_size + 1)\n","total_profit = 0\n","is_eval = True\n","done = False\n","states_sell_test = []\n","states_buy_test = []\n","\n","#Get the trained model\n","# model_name = f\"{dataset_dir}/model_ep\" +\"6\"\n","# agent = DQN_Agent(window_size, is_eval, model_name)\n","state = getState(data, 0, window_size + 1)\n","total_profit = 0\n","agent_inventory = []\n","\n","for t in tqdm(range(l_test), desc = \"Testing Pipeline in progress\"):\n","    action = agent.act(state)\n","    #print(action)\n","    #set_trace()\n","    next_state = getState(test_data, t + 1, window_size + 1)\n","    reward = 0\n","\n","    if action == 1:\n","        agent_inventory.append(test_data[t])\n","        states_buy_test.append(t)\n","        print(f\"Buy:{test_data[t]}\")\n","\n","    elif action == 2 and len(agent_inventory) > 0:\n","        bought_price = agent_inventory.pop(0)\n","        reward = max(test_data[t] - bought_price, 0)\n","\n","        total_profit += test_data[t] - bought_price\n","        states_sell_test.append(t)\n","        print(f\"Sell: {test_data[t]} | profit: {test_data[t] - bought_price}\")\n","\n","    if t == l_test - 1:\n","        done = True\n","    agent.memory.append((state, action, reward, next_state, done))\n","    state = next_state\n","\n","    if done:\n","        print(\"------------------------------------------\")\n","        print(f\"Total Profit: {total_profit:.2f}\")\n","        print(\"------------------------------------------\")\n","\n","plot_behavior(test_data,states_buy_test, states_sell_test, total_profit)\n"]}]}