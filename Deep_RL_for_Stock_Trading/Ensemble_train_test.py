{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMW9O4rCw6UTreSd0yq1PXn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9_yPSUEFRnu9"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset,DataLoader\n","import torch.optim as optim\n","\n","import yfinance as yf\n","from collections import deque\n","import random\n","import math\n","from tqdm import tqdm\n","\n","dataset_dir = \"/content/drive/MyDrive/Deep_RL_for_Stock_Trading\"\n","\n","# Define the ticker symbol for NIFTY50\n","nifty50_ticker = \"^NSEI\"\n","\n","# Download the historical data for NIFTY50\n","nifty50_data = yf.download(nifty50_ticker, start=\"2010-01-01\", end=\"2019-08-08\")\n","\n","plt.plot(nifty50_data['Close'])\n","plt.show()\n","\n","file_name = f\"{dataset_dir}/data.csv\"\n","\n","# Save the DataFrame to a CSV file\n","nifty50_data.to_csv(file_name, index=False)\n","\n","print(f\"File Saved at {file_name}\")\n","\n","#Data Cleaning and EDA\n","null_values = nifty50_data.isna().values.any()\n","print(f\"Presence of Null value : {int(null_values)}\")\n","\n","if null_values:\n","  nifty50_data = nifty50_data.fillna(method = \"ffill\")\n","\n","#data splitting in 80-20% fashion for training and testing\n","X=list(nifty50_data[\"Close\"])\n","data=[float(x) for x in X]\n","test_size = 0.2\n","\n","train_data = data[:int(len(data)*(1-test_size))]\n","test_data = data[int(len(data)*(1-test_size)):]\n","\n","print(f\"Training Data shape : {len(train_data)} and Testing Data Shape : {len(test_data)}\")\n","\n","#final ensemble model\n","from collections import Counter\n","\n","def weighted_vote(actions, buy_weight=3, sell_weight=3):\n","    weighted_actions = []\n","    for action in actions:\n","        if action == 1:  # 'Buy' action\n","            weighted_actions.extend([action] * int(buy_weight))\n","        elif action == 2:  # 'Sell' action\n","            weighted_actions.extend([action] * int(sell_weight))\n","        else:\n","            weighted_actions.append(action)\n","\n","    # Use Counter to find the majority action\n","    action_counts = Counter(weighted_actions)\n","    final_action = action_counts.most_common(1)[0][0]\n","\n","    return final_action\n","\n","actions = [0, 2, 1]\n","final_action = weighted_vote(actions)\n","\n","#agent is already defined in the training set above.\n","l_test = len(test_data) - 1\n","state = getState(test_data, 0, window_size + 1)\n","total_profit = 0\n","is_eval = True\n","done = False\n","states_sell_test = []\n","states_buy_test = []\n","\n","#Get the trained model\n","model_name_1 = f\"{dataset_dir}/model_ep8\"\n","agent_1 = DQN_Agent(window_size, is_eval, model_name_1)\n","\n","model_name = f\"{dataset_dir}/model_ddqn_ep8\"\n","agent_2 = DDQN_Agent(window_size, is_eval, model_name)\n","\n","model_name = f\"{dataset_dir}/model_ddpg_ep8\"\n","agent_3 = DDPG_Agent(window_size, is_eval, model_name)\n","\n","state = getState(data, 0, window_size + 1)\n","total_profit = 0\n","agent_inventory = []\n","\n","for t in tqdm(range(l_test), desc = \"Testing Pipeline in progress\"):\n","    actions_1 = agent_1.act(state)\n","    actions_2 = agent_2.act(state)\n","    noise = agent_3.noise_generator.sample()\n","    action_3 = agent_3.act(state, noise)\n","    actions_3 = np.argmax(action_3)\n","\n","    action = [actions_1, actions_2, actions_3]\n","    actions = weighted_vote(action)\n","    next_state = getState(test_data, t + 1, window_size + 1)\n","    reward = 0\n","\n","    if actions == 1:\n","        agent_inventory.append(test_data[t])\n","        states_buy_test.append(t)\n","        print(f\"Buy:{test_data[t]}\")\n","\n","    elif actions == 2 and len(agent_inventory) > 0:\n","        bought_price = agent_inventory.pop(0)\n","        reward = max(test_data[t] - bought_price, 0)\n","\n","        total_profit += test_data[t] - bought_price\n","        states_sell_test.append(t)\n","        print(f\"Sell: {test_data[t]} | profit: {test_data[t] - bought_price}\")\n","\n","    if t == l_test - 1:\n","        done = True\n","    agent.memory.append((state, action, reward, next_state, done))\n","    state = next_state\n","\n","    if done:\n","        print(\"------------------------------------------\")\n","        print(f\"Total Profit: {total_profit:.2f}\")\n","        print(\"------------------------------------------\")\n","\n","plot_behavior(test_data,states_buy_test, states_sell_test, total_profit)"]}]}